GM12878 enhancers:
-dataset originale: 65423 rows x 104 columns

-processato: 65423 rows x 104 columns

GM12878 promoters:
-dataset originale: 99909 rows x 104 columns

-processato: 99908 rows x 104 columns




experiment_setup:

experiment_id = 1
    dataset_type = 'epigenomic'
    cell_line, window_size, epigenomic_type = 'GM12878', 200, 'enhancers'
    n_split, test_size, random_state = 10, 0.2, 1
    balance = None #'under_sample' #SMOTE
    save_results = True
    dataset_row_reduction = None
    execute_pipeline = False #True
    defined_algorithms = define_models()
    holdout_parameters = (n_split, test_size, random_state)
    data_parameters = ((cell_line, window_size, epigenomic_type), dataset_type)
    alphas = [0.05]
    experiment = Experiment(experiment_id, data_parameters, holdout_parameters, alphas, defined_algorithms, balance,
                            save_results, dataset_row_reduction, execute_pipeline)
    experiment.execute()
    experiment.evaluate()
    experiment.print_model_info('all')

    make_visualization('experiment_results')















wilcoxon aggiustato: 

---- Best models ----enhancers
('decision_tree_2', (0.05, 'accuracy_score', 0.8218570882690104))
('decision_tree_2', (0.05, 'average_precision_score', 0.5326223892263697))
('decision_tree_1 e settantacinque',
 (0.05, 'balanced_accuracy_score', 0.720120316091739))
('decision_tree_1 e settantacinque',
 (0.05, 'roc_auc_score', 0.7201203160917391))


---- Best models ---- promoters
('decision_tree_2', (0.05, 'accuracy_score', 0.884761285156641))
('decision_tree_1 e settantacinque',
 (0.05, 'average_precision_score', 0.2256887337891174))
('decision_tree_1', (0.05, 'balanced_accuracy_score', 0.648119373639381))
('decision_tree_1', (0.05, 'roc_auc_score', 0.648119373639381))


---- Best models ----enhancers
('random_forest_1', (0.05, 'accuracy_score', 0.8301795949560565))
('random_forest_1', (0.05, 'average_precision_score', 0.5521063046638092))
('random_forest_1', (0.05, 'balanced_accuracy_score', 0.7362392110649505))
('random_forest_1', (0.05, 'roc_auc_score', 0.7362392110649505))


---- Best models ----promoters
('random_forest_7', (0.05, 'accuracy_score', 0.8873986587929137))
('random_forest_1', (0.05, 'average_precision_score', 0.20746223811646672))
('random_forest_1', (0.05, 'balanced_accuracy_score', 0.6045255932792801))
('random_forest_1', (0.05, 'roc_auc_score', 0.60452559327928))



---- Best models ----enhancers
('SGD_1', (0.05, 'accuracy_score', 0.8040122277416888))
('SGD_1', (0.05, 'average_precision_score', 0.49652385942931054))
('SGD_1', (0.05, 'balanced_accuracy_score', 0.7088132935441023))
('SGD_1', (0.05, 'roc_auc_score', 0.7088132935441023))



---- Best models ----promoters
('SGD_2', (0.05, 'accuracy_score', 0.8742968671804624))
('SGD_1', (0.05, 'average_precision_score', 0.23343023882397523))
('SGD_3', (0.05, 'balanced_accuracy_score', 0.7657665731391987))
('SGD_3', (0.05, 'roc_auc_score', 0.7657665731391987))








GM12878 nn + best models degli ehnancers

metrica di scelta mc: average precision


---- Best models ----
('Perceptron', (0.05, 'accuracy_score', 0.8292472296522735))
('encoder_FFNN', (0.05, 'average_precision_score', 0.759296358615501))
('FFNN_1', (0.05, 'balanced_accuracy_score', 0.7424297183619915))
('Perceptron', (0.05, 'roc_auc_score', 0.8488750754064963))
Rendering barplots: 100%|██████████| 4/4 [00:01<00:00,  3.94it/s]




modelli:

Input_layer = Input(shape=(104,)) 
    activation_function = "relu"

    initializer = 'random_uniform'
    regularizer = tf.keras.regularizers.l2(0.01) 

    init_bias = tf.keras.initializers.Zeros()




    nn_input_dimension = 104
    nf = 50 
    x = Dense(units=nf, activation='relu', kernel_initializer=initializer)(Input_layer)
    x = Dense(units=nn_input_dimension, activation='relu', kernel_initializer=initializer)(x)
    encoded = Dense(units=nf, activation='relu', kernel_initializer=initializer)(x)
    encoder = Model(Input_layer, encoded)


    models = {

        'NN':
            [
                ["Perceptron",
                 (
                     ([
                        Input_layer,
                        Dense(1, activation="sigmoid")
                    ],),

                     dict(
                         optimizer='nadam',
                         loss='binary_crossentropy'
                     ),

                     dict(
                             epochs=1000,
                             batch_size=1024,
                             validation_split=0.1,
                             shuffle=True,
                             verbose=False,
                             callbacks=[
                                 EarlyStopping(monitor="val_loss", mode="min", patience=50),
                             ]
                         )

                 )],

                ['FFNN_1',
                 (
                     ([
                         Input_layer,
                         Dense(256, activation=activation_function),
                         Dense(128),
                         BatchNormalization(),
                         Activation('relu'),
                         Dense(64, activation=activation_function),
                         Dropout(0.3),
                         Dense(32, activation=activation_function),
                         Dense(16, activation=activation_function),
                         Dense(1, activation="sigmoid")
                     ],),

                     dict(
                         optimizer='nadam',
                         loss='binary_crossentropy'
                     ),

                     dict(
                        epochs=1000,
                        batch_size=1024,
                        validation_split=0.1,
                        shuffle=True,
                        verbose=True,
                        # class_weight=class_weightz,
                        callbacks=[
                            EarlyStopping(monitor="val_loss", mode="min", patience=10),
                        ]
                    )

                 )],

                ['FFNN_2',
                 (
                     ([
                         Input_layer,
                         Dense(512, activation=activation_function, kernel_initializer=initializer),
                         Dense(512, activation=activation_function, kernel_initializer=initializer),
                         Dropout(0.2),
                         Dense(256, activation=activation_function, kernel_initializer=initializer),
                         Dense(256, activation=activation_function, kernel_initializer=initializer),
                         Dropout(0.3),
                         Dense(128),
                         BatchNormalization(),
                         Activation(activation_function),
                         Dense(128, activation=activation_function, kernel_initializer=initializer),
                         Dense(64, activation=activation_function, kernel_initializer=initializer),
                         Dropout(0.3),
                         Dense(64, activation=activation_function, kernel_initializer=initializer),
                         Dense(16, activation=activation_function, kernel_initializer=initializer),
                         Dense(8, activation=activation_function, kernel_initializer=initializer),
                         Dense(1, activation="sigmoid")
                     ],),

                     dict(
                         optimizer='nadam',
                         loss='binary_crossentropy'
                     ),

                     dict(
                        epochs=1000,
                        batch_size=1024,
                        validation_split=0.1,
                        shuffle=True,
                        verbose=True,
                        callbacks=[
                            EarlyStopping(monitor="val_loss", mode="min", patience=50),
                        ]
                    )

                 )],

                ['encoder_FFNN',
                 (
                     ([
                         encoder,




                         Dense(256),
                         BatchNormalization(),
                         Activation('relu'),
                         Dense(128, activation=activation_function, kernel_initializer=initializer,
                               activity_regularizer=regularizer),




                         Dropout(0.2),
                         Dense(32, activation=activation_function, kernel_initializer=initializer,
                               activity_regularizer=regularizer),
                         Dropout(0.2),
                         Dense(16, activation=activation_function, kernel_initializer=initializer,
                               activity_regularizer=regularizer),
                         Dropout(0.2),
                         Dense(1, activation="sigmoid", bias_initializer=init_bias)
                     ],),

                     dict(
                         optimizer='nadam',
                         loss='binary_crossentropy'
                     ),

                     dict(
                        epochs=1000,
                        batch_size=512,
                        validation_split=0.1,
                        shuffle=True,
                        verbose=False,
                        # class_weight=class_weightz,
                        callbacks=[
                            EarlyStopping(monitor="val_loss", mode="min", patience=10, restore_best_weights=True),
                            # learning_rate_scheduler
                        ]
                    )

                 )]

            ],

        'SGD': [

            ['SGD',#'SGD_1',
             dict(
               loss='hinge',
               penalty='l2',
               n_jobs=cpu_count(),
               random_state=1,
               class_weight=None
             )


        ],

        'RandomForest': [
            ['Random Forest',#'random_forest_1',
             dict(
                 random_state=1,
                 n_jobs=cpu_count(),

             )]
 

        ],

        'DecisionTree': [
           
            ['Decision Tree',#'decision_tree_2',
             dict(
                 max_depth=5
             )]
        ]



    }




GM12878 nn + best models degli promoters

metrica: average precisions


---- Best models ----
('Perceptron', (0.05, 'accuracy_score', 0.8834350915824242))
('FFNN_1', (0.05, 'average_precision_score', 0.45563388620875267))
('FFNN_1', (0.05, 'balanced_accuracy_score', 0.6445105797411151))
('FFNN_1', (0.05, 'roc_auc_score', 0.8854409704181027))
Rendering barplots: 100%|██████████| 4/4 [00:01<00:00,  3.86it/s]



nn uguali


'SGD': [

            ['SGD',#'SGD_1',
             dict(
               loss='hinge',
               penalty='l2',
               n_jobs=cpu_count(),
               random_state=1,
               class_weight=None
             )
            ]

        ],

        'RandomForest': [
            ['Random Forest',#'random_forest_1',
             dict(
                 random_state=1,
                 n_jobs=cpu_count(),

             )]

        ],

        'DecisionTree': [
    
            ['Decision Tree',#'decision_tree_1 e settantacinque',
             dict(
                 min_samples_leaf=20,
                 min_samples_split=20
             )]
        ]




